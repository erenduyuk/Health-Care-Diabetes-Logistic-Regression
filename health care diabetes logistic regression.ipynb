{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2935d7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries to be used are included\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "import copy\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d60ed772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data uploaded\n",
    "data = pd.read_csv(\"health care diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea895a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "443391ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data values and dependent variable\n",
    "x_train = data.drop(\"Outcome\", axis=1).values\n",
    "y_train = data[\"Outcome\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d57b3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of x_train: <class 'numpy.ndarray'>\n",
      "Type of y_train: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of x_train:\", type(x_train))\n",
    "print(\"Type of y_train:\", type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5885379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of x_train is: (768, 8)\n",
      "The shape of y_train is: (768,)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of x_train is:\", x_train.shape)\n",
    "print(\"The shape of y_train is:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f8c6759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five elements of x_train: [[6.000e+00 1.480e+02 7.200e+01 3.500e+01 0.000e+00 3.360e+01 6.270e-01\n",
      "  5.000e+01]\n",
      " [1.000e+00 8.500e+01 6.600e+01 2.900e+01 0.000e+00 2.660e+01 3.510e-01\n",
      "  3.100e+01]\n",
      " [8.000e+00 1.830e+02 6.400e+01 0.000e+00 0.000e+00 2.330e+01 6.720e-01\n",
      "  3.200e+01]\n",
      " [1.000e+00 8.900e+01 6.600e+01 2.300e+01 9.400e+01 2.810e+01 1.670e-01\n",
      "  2.100e+01]\n",
      " [0.000e+00 1.370e+02 4.000e+01 3.500e+01 1.680e+02 4.310e+01 2.288e+00\n",
      "  3.300e+01]]\n",
      "First five elements of y_train: [1 0 1 0 1]\n",
      "Number of training examples(m): 768\n"
     ]
    }
   ],
   "source": [
    "print(\"First five elements of x_train:\", x_train[:5])\n",
    "print(\"First five elements of y_train:\", y_train[:5])\n",
    "print(\"Number of training examples(m):\", len(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d74b27",
   "metadata": {},
   "source": [
    "### Sigmoid function\n",
    "\n",
    "Recall that for logistic regression, the model is represented as\n",
    "\n",
    "$$ f_{\\mathbf{w},b}(x) = g(\\mathbf{w}\\cdot \\mathbf{x} + b)$$\n",
    "where function $g$ is the sigmoid function. The sigmoid function is defined as:\n",
    "\n",
    "$$g(z) = \\frac{1}{1+e^{-z}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d696b2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    g = 1 / (1 + math.e ** -z)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46e4b511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid([ -1, 0, 1, 2]) = [0.26894142 0.5        0.73105858 0.88079708]\n"
     ]
    }
   ],
   "source": [
    "# Test for sigmoid function\n",
    "print (\"sigmoid([ -1, 0, 1, 2]) = \" + str(sigmoid(np.array([-1, 0, 1, 2]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7ed965",
   "metadata": {},
   "source": [
    "## Cost Function\n",
    "\n",
    "The cost function is calculated with following formulas\n",
    "\n",
    "$$ J(\\mathbf{w},b) = \\frac{1}{m}\\sum_{i=0}^{m-1} \\left[ loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) \\right] \\tag{1}$$\n",
    "\n",
    "\n",
    "$$loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) = (-y^{(i)} \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) \\tag{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54b81661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(x, y, w, b, *argv):\n",
    "    m, n = x.shape # m is row n is column\n",
    "    \n",
    "    total_cost = 0\n",
    "    f_wb = 0\n",
    "    \n",
    "    for i in range(m):\n",
    "        f_wb = 0\n",
    "        for j in range(n):\n",
    "            f_wb_ij = w[j] * x[i][j]\n",
    "            f_wb += f_wb_ij\n",
    "        f_wb += b\n",
    "        loss = sigmoid(f_wb)\n",
    "        total_cost += (-y[i] * math.log(loss)) - ((1 - y[i]) * math.log(1 - loss))\n",
    "        \n",
    "    total_cost /= m\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eda527c",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "The gradient descent is calculated with following formulas\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - \\mathbf{y}^{(i)}) \\tag{2}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - \\mathbf{y}^{(i)})x_{j}^{(i)} \\tag{3}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "298ca626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(x, y, w, b, *argv):\n",
    "    m, n = x.shape\n",
    "    dj_dw = np.zeros(w.shape)\n",
    "    dj_db = 0\n",
    "    \n",
    "    for i in range(m):\n",
    "        z_wb = 0\n",
    "        for j in range(n):\n",
    "            z_wb += w[j] * x[i][j]\n",
    "        z_wb += b\n",
    "        f_wb = sigmoid(z_wb)\n",
    "        \n",
    "        dj_db_i = f_wb - y[i]\n",
    "        dj_db += dj_db_i\n",
    "        \n",
    "        for j in range(n):\n",
    "            dj_dw_ij = (f_wb - y[i]) * x[i][j]\n",
    "            dj_dw[j] += dj_dw_ij\n",
    "            \n",
    "    dj_dw /= m\n",
    "    dj_db /= m\n",
    "\n",
    "        \n",
    "    return dj_db, dj_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b992955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters, lambda_): \n",
    "    \n",
    "    m = len(x)\n",
    "    \n",
    "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
    "    J_history = []\n",
    "    w_history = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Calculate the gradient and update the parameters\n",
    "        dj_db, dj_dw = gradient_function(x, y, w_in, b_in, lambda_)   \n",
    "\n",
    "        # Update Parameters using w, b, alpha and gradient\n",
    "        w_in = w_in - alpha * dj_dw               \n",
    "        b_in = b_in - alpha * dj_db              \n",
    "       \n",
    "        # Save cost J at each iteration\n",
    "        if i<100000:      # prevent resource exhaustion \n",
    "            cost =  cost_function(x, y, w_in, b_in, lambda_)\n",
    "            J_history.append(cost)\n",
    "\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i% math.ceil(num_iters/10) == 0 or i == (num_iters-1):\n",
    "            w_history.append(w_in)\n",
    "            print(f\"Iteration {i:4}: Cost {float(J_history[-1]):8.2f}   \")\n",
    "        \n",
    "    return w_in, b_in, J_history, w_history #return w and J,w history for graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "550e75d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost     2.55   \n",
      "Iteration 1000: Cost     0.49   \n",
      "Iteration 2000: Cost     0.48   \n",
      "Iteration 3000: Cost     0.48   \n",
      "Iteration 4000: Cost     0.48   \n",
      "Iteration 5000: Cost     0.48   \n",
      "Iteration 6000: Cost     0.48   \n",
      "Iteration 7000: Cost     0.48   \n",
      "Iteration 8000: Cost     0.48   \n",
      "Iteration 9000: Cost     0.48   \n",
      "Iteration 9999: Cost     0.48   \n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "initial_w = 0.01 * (np.random.rand(8) - 0.5)\n",
    "initial_b = -8\n",
    "\n",
    "# Some gradient descent settings\n",
    "iterations = 10000\n",
    "alpha = 0.0001\n",
    "\n",
    "w,b, J_history,_ = gradient_descent(x_train ,y_train, initial_w, initial_b, \n",
    "                                   compute_cost, compute_gradient, alpha, iterations, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "034a6160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, w, b): \n",
    "\n",
    "    # number of training examples\n",
    "    m, n = x.shape   \n",
    "    p = np.zeros(m)\n",
    "   \n",
    "    for i in range(m):   \n",
    "        z_wb = 0\n",
    "        for j in range(n): \n",
    "            z_wb += w[j] * x[i][j]\n",
    "    \n",
    "        z_wb += b\n",
    "        \n",
    "        # Calculate the prediction\n",
    "        f_wb = sigmoid(z_wb)\n",
    "\n",
    "        p[i] = 0 if f_wb < 0.5 else 1\n",
    "        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30fe6e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 77.213542\n"
     ]
    }
   ],
   "source": [
    "p = predict(x_train, w,b)\n",
    "print('Train Accuracy: %f'%(np.mean(p == y_train) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3715b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
